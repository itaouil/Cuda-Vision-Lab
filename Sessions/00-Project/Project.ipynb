{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project 1: Self-supervised Video Prediction\n",
    "\n",
    "- Implement the following model, and train it on trainset:\n",
    "\n",
    "<img src=\"NimbRoPred.png\"/>\n",
    "\n",
    "<font color=\"red\" size=\"5\">The model is unpublished, so do not distribute it.</font>\n",
    "\n",
    "- Note that the model is inspired by https://arxiv.org/abs/1612.01756, and: [winner2019.pdf](winner2019.pdf)\n",
    "\n",
    "- Use DSSIM+L2 loss for training. Find the right balance of the gains.\n",
    "\n",
    "- Generate some GIFs of the results on the test dataset. Like below, draw a green and red frame to show the prediction phase.\n",
    "\n",
    "<img src=\"res1.gif\"/>\n",
    "<img src=\"res2.gif\"/>\n",
    "<img src=\"res3.gif\"/>\n",
    "\n",
    "- Pay attention that two of the ladder layers have location dependant-convolution paper: http://ais.uni-bonn.de/~hfarazi/papers/LocDep.pdf\n",
    "Code: https://github.com/AIS-Bonn/LocDepVideoPrediction\n",
    "\n",
    "- Use three seed frames and predict the next three frames in an autoregressive manner: \n",
    "    - Input: GT0 Discard output\n",
    "    - Input: GT1 Discard output\n",
    "    - Input: GT2 Output should be Pred0 (calculate the loss between Pred0 and GT3)\n",
    "    - Input: Pred0 Output should be Pred1 (calculate the loss between Pred1 and GT4)\n",
    "    - Input: Pred1 Output should be Pred2 (calculate the loss between Pred2 and GT5)\n",
    "\n",
    "- Use the resolution 320x224 for the real dataset. Pay attention to the aspect ratio.\n",
    "\n",
    "- To ensure that your implementation is bug-free, first test it on the synthetic dataset.\n",
    "\n",
    "- Try to adjust the hyper-parameters of the model to achieve the best performance possible.\n",
    "\n",
    "- (Extra points) Add adversarial loss and random vector \"Z\" to the model.\n",
    "\n",
    "- (Extra points) Suggest your own model and compare its performance with existing ones.\n",
    "\n",
    "## DataSet\n",
    "\n",
    "### Real Dataset:\n",
    "- Use these youtube videos:\n",
    "    https://www.youtube.com/watch?v=yyLa6xIK9Qs\n",
    "    \n",
    "    https://www.youtube.com/watch?v=_bR-usQb4UE\n",
    "    \n",
    "    https://www.youtube.com/watch?v=ITe-seb4PsA\n",
    "    \n",
    "    https://www.youtube.com/watch?v=TPgRR3HoSDw\n",
    "    \n",
    "    https://www.youtube.com/watch?v=qmYSt3nVJpA\n",
    "    \n",
    "    https://www.youtube.com/watch?v=tPktQyFrMuw\n",
    "    \n",
    "    https://www.youtube.com/watch?v=IwWt8CS_oBg\n",
    "    \n",
    "    https://www.youtube.com/watch?v=UsmBD2_3FH8\n",
    "    \n",
    "    https://www.youtube.com/watch?v=h4Kds-RiuYM\n",
    "    \n",
    "    https://www.youtube.com/watch?v=9FvMW2PcBeA\n",
    "    \n",
    "    https://www.youtube.com/watch?v=5w2tdfEQzac\n",
    "    \n",
    "    https://www.youtube.com/watch?v=WGKo_6IkFBY\n",
    "    \n",
    "    https://www.youtube.com/watch?v=sL-BEltQy9k\n",
    "    \n",
    "    https://www.youtube.com/watch?v=qk4qXXJcaZk\n",
    "    \n",
    "    https://www.youtube.com/watch?v=NlrEaU50Mw4\n",
    "    \n",
    "Split the videos to 80% train - 20% Validation\n",
    "\n",
    "- Test set (report your results on this video):\n",
    "    https://www.youtube.com/watch?v=yVdB_0ry53o\n",
    "    \n",
    "### Synthetic Datasets (Moving MNIST):\n",
    "\n",
    "- http://www.cs.toronto.edu/~nitish/unsupervised_video/\n",
    "\n",
    "## Objectives\n",
    "- Implement and test the given self-supervised model for video prediction on two datasets.\n",
    "- Get the best result possible.\n",
    "- Write the final lab report.\n",
    "\n",
    "\n",
    "## For:\n",
    "\n",
    "Sreenivasa Hikkal Venugopala - Shravanthi Arvind Patil\n",
    "\n",
    "Ruben Vasquez - Rohil Rao\n",
    "\n",
    "Ruihua Hu - Sanket Shah\n",
    "\n",
    "Yifan Yang - Sugan Kanagasenthinathan\n",
    "\n",
    "Ani Karapetyan - Vladimir Tsaturyan\n",
    "\n",
    "Gautam Kumar Jain - Jannis Horn\n",
    "\n",
    "Varun Shankar\n",
    "\n",
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project 2: Soccer Robot Perception\n",
    "\n",
    "- Implement the model in [winner2019.pdf](winner2019.pdf) for detecting ball, goalposts, and robots as well as pixel-wise segmentation of filed and lines. You need to have three output channels for the detection head and three additional output channels for the segmentation head.\n",
    "- Implement and train the model with training datasets.\n",
    "- Measure and report Recall, accuracy, precision, F1, and False detection rate for detection. Measure and report accuracy and IOU for classification. Measurement should be on unseen test dataset. Try to adjust the hyper-parameters of the model to achieve the best performance possible.\n",
    "- (Optional) Suggest your own model and compare its performance with existing ones.\n",
    "\n",
    "<img src=\"model.png\"/>\n",
    "\n",
    "\n",
    "<img src=\"res1.png\"/>\n",
    "\n",
    "\n",
    "<img src=\"res2.png\"/>\n",
    "\n",
    "\n",
    "<img src=\"table.png\"/>\n",
    "\n",
    "\n",
    "## DataSet\n",
    "- http://bigcuda5.informatik.uni-bonn.de:8686/\n",
    "(Don't forget to include ForceTrain and ForceTest)\n",
    "\n",
    "Split the videos to 70% train - 15% Validation - 15% Test\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Implement the model in [winner2019.pdf](winner2019.pdf) for detecting ball, goalposts, and robots as well as pixel-wise segmentation of filed and lines.\n",
    "- Get the best result possible.\n",
    "- Write the final lab report.\n",
    "\n",
    "## For:\n",
    "\n",
    "Prajakta Bhujbal - Noopur Rai\n",
    "\n",
    "Ilyass Taouil - Youssef Shoeb\n",
    "\n",
    "Deepan Chakravarthi Padmanabhan - Mihir Mulye\n",
    "\n",
    "Ludovico Scarton - Kajal Puri\n",
    "\n",
    "Lokesh Veeramacheneni - Ragith Ayyappan Kutty\n",
    "\n",
    "Venkata Santosh Sai Ramireddy Muthireddy - Jaswanth Bandlamudi\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Important dates \n",
    "- 15/03 : Draft submission due \n",
    "- 15/03 - 09/04: Revision period \n",
    "- 15/04: Report submission final due\n",
    "\n",
    "## Lab report\n",
    "- Use the LaTeX template [template.zip](template.zip). The main idea is to practice a small \"thesis\".\n",
    "- Write a nice, readable introduction. Describe which methods you have used, including some maths, put your results in a table, include a figure (both with caption), reference table, and figure in your text when you discuss the results. Write a conclusion.\n",
    "- Make sure to cite correctly. Ensure you do not copy from anywhere without citing the source when you refer codes from open source community.\n",
    "- Write an abstract that summarizes everything you wrote. Use a spell checker and/or let somebody else read your report before submitting it. \n",
    "- Your lab report should have 6-8 pages. Margins are fairly wide, so there isn't much to write. Try to be brief but readable and informative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
