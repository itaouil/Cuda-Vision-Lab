{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dont name your email subject anything other than Assignment# !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd: Automatic Differentiation\n",
    "===================================\n",
    "\n",
    "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
    "Let’s first briefly visit this, and we will then go to training our\n",
    "first neural network.\n",
    "\n",
    "\n",
    "The ``autograd`` package provides automatic differentiation for all operations\n",
    "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
    "defined by how your code is run, and that every single iteration can be\n",
    "different.\n",
    "\n",
    "Let us see this in more simple terms with some examples.\n",
    "\n",
    "Tensor\n",
    "--------\n",
    "\n",
    "``torch.Tensor`` is the central class of the package. If you set its attribute\n",
    "``.requires_grad`` as ``True``, it starts to track all operations on it. When\n",
    "you finish your computation you can call ``.backward()`` and have all the\n",
    "gradients computed automatically. The gradient for this tensor will be\n",
    "accumulated into ``.grad`` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
    "it from the computation history, and to prevent future computation from being\n",
    "tracked.\n",
    "\n",
    "To prevent tracking history (and using memory), you can also wrap the code block\n",
    "in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n",
    "model because the model may have trainable parameters with\n",
    "``requires_grad=True``, but for which we don't need the gradients.\n",
    "\n",
    "There’s one more class which is very important for autograd\n",
    "implementation - a ``Function``.\n",
    "\n",
    "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. Each tensor has\n",
    "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Tensor`` (except for Tensors created by the user - their\n",
    "``grad_fn is None``).\n",
    "\n",
    "If you want to compute the derivatives, you can call ``.backward()`` on\n",
    "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
    "data), you don’t need to specify any arguments to ``backward()``,\n",
    "however if it has more elements, you need to specify a ``gradient``\n",
    "argument that is a tensor of matching shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
    "flag in-place. The input flag defaults to ``False`` if not given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x124f15320>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We dont need to specify requires_grad = False, since by default it flags it as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.Tensor([[1, 2, 3], \n",
    "                       [4, 5, 6]])\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.Tensor([[7, 8, 9], \n",
    "                        [10, 11, 12]])\n",
    "\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property defines whether to track operations on this tensor\n",
    "By default, it is set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires\\_grad\\_() function sets requires_grad to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .grad property stores all the gradients for the tensor\n",
    "However, there are no gradients yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .grad_fn property contains the gradient function\n",
    "This has not been set either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new output tensor from our original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property has been derived from the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are still no gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hafez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But there is a gradient function\n",
    "This is from the multiplication operation performed on the original tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x7fa4fff991d0>\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The original tensor still does not have a gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor2.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the operation for the output changes the gradient function\n",
    "The gradient function only contains the last operation. Here, even though there is a multiplication as well as a mean, only the mean calculation is recorded as the gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward0 object at 0x7fa4fff99ed0>\n"
     ]
    }
   ],
   "source": [
    "output_tensor = (tensor1 * tensor2).mean()\n",
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In spite of setting a gradient function for the output, the gradients for the input tensor is still empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate the gradients, we need to explicitly perform a backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradients are now available for the input tensor\n",
    "\n",
    "Future calls to backward will accumulate gradients into this vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1667, 1.3333, 1.5000],\n",
      "        [1.6667, 1.8333, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient vector is the same shape as the original vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.grad.shape, tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hafez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property propagates to other tensors\n",
    "Here the new_tensor is created from the original tensor and gets the original's value of requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "new_tensor = tensor1 * 3\n",
    "print(new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9.],\n",
       "        [12., 15., 18.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning off gradient calculations for tensors\n",
    "You can also stops autograd from tracking history on newly created tensors with requires_grad=True by wrapping the code block in <br />\n",
    "<b>with torch.no_grad():</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "requires_grad for tensor =  True\n",
      "requires_grad for tensor =  False\n",
      "requires_grad for new_tensor =  False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    new_tensor = tensor1 * 3\n",
    "    \n",
    "    print('new_tensor = ', new_tensor)\n",
    "    \n",
    "    print('requires_grad for tensor = ', tensor1.requires_grad)\n",
    "    \n",
    "    print('requires_grad for tensor = ', tensor2.requires_grad)\n",
    "    \n",
    "    print('requires_grad for new_tensor = ', new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can turn off gradient calculations performed within a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_with_no_grad(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor = calculate(tensor1)\n",
    "\n",
    "result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad = calculate_with_no_grad(tensor1)\n",
    "\n",
    "result_tensor_no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can explicitly enabled gradients within a no_grad() context\n",
    "\n",
    "There is an equivalent @torch.enable_grad() as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor_no_grad =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "new_tensor_grad =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    new_tensor_no_grad = tensor1 * 3\n",
    "    \n",
    "    print('new_tensor_no_grad = ', new_tensor_no_grad)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        \n",
    "        new_tensor_grad = tensor1 * 3\n",
    "    \n",
    "        print('new_tensor_grad = ', new_tensor_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result tensors get requires_grad properties from input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one = torch.tensor([[1.0, 2.0], \n",
    "                           [3.0, 4.0]], requires_grad=True)  \n",
    "tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_two = torch.Tensor([[5, 6], \n",
    "                           [7, 8]])\n",
    "tensor_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enable the gradients for  two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_two.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor = (tensor_one + tensor_two).mean()\n",
    "final_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### final tensor has gradients enabled as it derives from the tensors its made up of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hafez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(final_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detach tensors from the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_tensor = tensor_one.detach()\n",
    "\n",
    "detached_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tensor = (tensor_one + detached_tensor).mean()\n",
    "\n",
    "mean_tensor.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace It your self!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 2).requires_grad_()\n",
    "a = ((a * 3) / (a - 1))\n",
    "b = (a * a).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a88862ab5c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#look at https://github.com/szagoruyko/pytorchviz\n",
    "def make_dot(var, params):\n",
    "    param_map = {id(v): k for k, v in params.items()}\n",
    "    \n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    \n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d'% v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "g = make_dot(b,{})\n",
    "g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'SumBackward0'>\n",
      "<class 'MulBackward0'>\n",
      "<class 'DivBackward0'>\n",
      "<class 'MulBackward0'>\n",
      "<class 'SubBackward0'>\n",
      "<class 'DivBackward0'>\n",
      "<class 'MulBackward0'>\n",
      "<class 'SubBackward0'>\n"
     ]
    }
   ],
   "source": [
    "def trackIt(inp):\n",
    "    if inp is None:\n",
    "        return None\n",
    "    if hasattr(inp,'grad_fn'):\n",
    "        print(type(inp.grad_fn))\n",
    "        trackIt(inp.grad_fn.next_functions)\n",
    "        return None\n",
    "    if type(inp) is tuple:\n",
    "        for u in inp:\n",
    "            trackIt(u[0])\n",
    "        return None\n",
    "    if hasattr(inp, 'next_functions'):\n",
    "        if \"AccumulateGrad\" not in str(type(inp)):\n",
    "            print(type(inp))\n",
    "        trackIt(inp.next_functions)\n",
    "        return None\n",
    "\n",
    "trackIt(b) #Trace it your self!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create a Variable with Float tensor\n",
    "\n",
    "The return value is not a variable instead it is a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = Variable(torch.FloatTensor([9]))\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create two weight variables with gradients enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.FloatTensor([3]), requires_grad = True)\n",
    "w2 = Variable(torch.FloatTensor([7]), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create two more variables using the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_var = var * w1\n",
    "\n",
    "result_var "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New variables derive enabled gradients from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_var.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_var.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients\n",
    "---------\n",
    "Let's backprop now.\n",
    "Because ``out`` contains a single scalar, ``out.backward()`` is\n",
    "equivalent to ``out.backward(torch.tensor(1.))``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor and set ``requires_grad=True`` to track computation with it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a tensor operation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7fa4fffe69d0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do more operations on ``y``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print gradients d(out)/dx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Tensor* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n",
    "Mathematically, if you have a vector valued function $\\vec{y}=f(\\vec{x})$,\n",
    "then the gradient of $\\vec{y}$ with respect to $\\vec{x}$\n",
    "is a Jacobian matrix:\n",
    "\n",
    "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "Generally speaking, ``torch.autograd`` is an engine for computing\n",
    "vector-Jacobian product. That is, given any vector\n",
    "$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$,\n",
    "compute the product $v^{T}\\cdot J$. If $v$ happens to be\n",
    "the gradient of a scalar function $l=g\\left(\\vec{y}\\right)$,\n",
    "that is,\n",
    "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$,\n",
    "then by the chain rule, the vector-Jacobian product would be the\n",
    "gradient of $l$ with respect to $\\vec{x}$:\n",
    "\n",
    "\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial y_{m}}\n",
    "   \\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "(Note that $v^{T}\\cdot J$ gives a row vector which can be\n",
    "treated as a column vector by taking $J^{T}\\cdot v$.)\n",
    "\n",
    "This characteristic of vector-Jacobian product makes it very\n",
    "convenient to feed external gradients into a model that has\n",
    "non-scalar output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at an example of vector-Jacobian product:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([594.0493, 253.0711, 924.7622], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in this case ``y`` is no longer a scalar. ``torch.autograd``\n",
    "could not compute the full Jacobian directly, but if we just\n",
    "want the vector-Jacobian product, simply pass the vector to\n",
    "``backward`` as argument:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stop autograd from tracking history on Tensors\n",
    "with ``.requires_grad=True`` by wrapping the code block in\n",
    "``with torch.no_grad():``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<class 'AddBackward0'>\n",
      "<class 'torch.autograd.function.mysinBackward'>\n",
      "<class 'SumBackward0'>\n",
      "<class 'MulBackward0'>\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class mysin(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,i):\n",
    "        ctx.save_for_backward(i)\n",
    "        return i.sin()\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        print(\"my backward called\")\n",
    "        i, = ctx.saved_tensors\n",
    "        return grad_output*i.cos()\n",
    "    \n",
    "\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "t = (a * a).sum()\n",
    "b = mysin.apply(t)\n",
    "b = b+1\n",
    "trackIt(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my backward called\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-1790925d726b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Read more:https://pytorch.org/docs/master/notes/extending.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "b.backward()\n",
    "print(inp.grad)\n",
    "\n",
    "#Read more:https://pytorch.org/docs/master/notes/extending.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Later:**\n",
    "\n",
    "Documentation of ``autograd`` and ``Function`` is at\n",
    "https://pytorch.org/docs/autograd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "<img src=\"linreg1.jpg\">\n",
    "<img src=\"linreg2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataset\n",
    "A simple dataset using numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array ([[4.7], [2.4], [7.5], [7.1], [4.3], [7.816], \n",
    "                     [8.9], [5.2], [8.59], [2.1], [8] , \n",
    "                     [10], [4.5], [6], [4]],\n",
    "                    dtype = np.float32)\n",
    "\n",
    "y_train = np.array ([[2.6], [1.6], [3.09], [2.4], [2.4], [3.357], \n",
    "                     [2.6], [1.96], [3.53], [1.76], [3.2] , \n",
    "                     [3.5], [1.6], [2.5], [2.2]], \n",
    "                    dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the data\n",
    "There seems to be some relationship which can be plotted between x_train and y_train. A regression line can be drawn to represent the relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(x_train, y_train, label='Original data', s=250, c='g')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data to pytorch tensors\n",
    "By defualt requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad for X_train:  False\n",
      "requires_grad for Y_train:  False\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(x_train) \n",
    "Y_train = torch.from_numpy(y_train)\n",
    "\n",
    "print('requires_grad for X_train: ', X_train.requires_grad)\n",
    "print('requires_grad for Y_train: ', Y_train.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the details for our neural network\n",
    "Input, output and hidden layer sizes plus the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 \n",
    "hidden_size = 1\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create random Tensors for weights.<br>\n",
    "Setting requires_grad=True indicates that we want to compute gradients with respect to these Tensors during the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.rand(input_size, \n",
    "                hidden_size, \n",
    "                \n",
    "                requires_grad=True)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = torch.rand(hidden_size, \n",
    "                output_size, \n",
    "                \n",
    "                requires_grad=True)\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "#### Foward Pass:\n",
    "* Predicting Y with input data X\n",
    "* finding (matrix X matrix) using .mm function, finding product of X_train and w1 and activation function is identity function\n",
    "* again doing mat product data with second weight w2\n",
    "\n",
    "#### Finding Loss:\n",
    "* Finding difference between Y_train and Y_pred by squaring the difference and then summing out, similar to nn.MSELoss \n",
    "\n",
    "\n",
    "#### For the loss_backward() function call:\n",
    "* backward pass will compute the gradient of loss with respect to all Tensors with requires_grad=True. \n",
    "* After this call w1.grad and w2.grad will be Tensors holding the gradient of the loss with respect to w1 and w2 respectively.\n",
    "\n",
    "#### Manually updating the weights\n",
    "* weights have requires_grad=True, but we don't need to track this in autograd. So will wrap it in torch.no_grad\n",
    "* reducing weight with multiple of learning rate and gradient\n",
    "* manually zero the weight gradients after updating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 35.97338104248047\n",
      "100 34.311439514160156\n",
      "150 32.70014190673828\n",
      "200 31.14057731628418\n",
      "250 29.633655548095703\n",
      "300 28.180097579956055\n",
      "350 26.780445098876953\n",
      "400 25.435075759887695\n",
      "450 24.1441707611084\n",
      "500 22.907690048217773\n",
      "550 21.725444793701172\n",
      "600 20.597030639648438\n",
      "650 19.521926879882812\n",
      "700 18.499374389648438\n",
      "750 17.52846908569336\n",
      "800 16.608234405517578\n",
      "850 15.737475395202637\n",
      "900 14.914917945861816\n",
      "950 14.139177322387695\n",
      "1000 13.408772468566895\n",
      "1050 12.722145080566406\n",
      "1100 12.07768726348877\n",
      "1150 11.473724365234375\n",
      "1200 10.90857219696045\n",
      "1250 10.380496978759766\n",
      "1300 9.887768745422363\n",
      "1350 9.428682327270508\n",
      "1400 9.00150203704834\n",
      "1450 8.604549407958984\n",
      "1500 8.236138343811035\n",
      "1550 7.894645690917969\n",
      "1600 7.5785017013549805\n",
      "1650 7.286149501800537\n",
      "1700 7.01611328125\n",
      "1750 6.7669525146484375\n",
      "1800 6.537304878234863\n",
      "1850 6.325829982757568\n",
      "1900 6.131318092346191\n",
      "1950 5.952566146850586\n",
      "2000 5.788446426391602\n",
      "2050 5.637892246246338\n",
      "2100 5.499894618988037\n",
      "2150 5.373514175415039\n",
      "2200 5.2578535079956055\n",
      "2250 5.152091979980469\n",
      "2300 5.055447578430176\n",
      "2350 4.967199802398682\n",
      "2400 4.886671543121338\n",
      "2450 4.813229560852051\n",
      "2500 4.746282577514648\n",
      "2550 4.685310363769531\n",
      "2600 4.629798889160156\n",
      "2650 4.579288959503174\n",
      "2700 4.533350944519043\n",
      "2750 4.491593360900879\n",
      "2800 4.453653812408447\n",
      "2850 4.419198989868164\n",
      "2900 4.38791561126709\n",
      "2950 4.359532356262207\n"
     ]
    }
   ],
   "source": [
    "# Start at 10. Change this to 100, 1000 and 3000 and run the code all the way to the plot at the bottom\n",
    "for iter in range(1, 3000):\n",
    "    \n",
    "    y_pred = X_train.mm(w1).mm(w2)\n",
    "    loss = (y_pred - Y_train).pow(2).sum()\n",
    "    \n",
    "    if iter % 50 ==0:\n",
    "        print(iter, loss.item())\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  tensor([[0.5272]], requires_grad=True)\n",
      "w2:  tensor([[0.7152]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print ('w1: ', w1)\n",
    "print ('w2: ', w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7000],\n",
       "        [ 2.4000],\n",
       "        [ 7.5000],\n",
       "        [ 7.1000],\n",
       "        [ 4.3000],\n",
       "        [ 7.8160],\n",
       "        [ 8.9000],\n",
       "        [ 5.2000],\n",
       "        [ 8.5900],\n",
       "        [ 2.1000],\n",
       "        [ 8.0000],\n",
       "        [10.0000],\n",
       "        [ 4.5000],\n",
       "        [ 6.0000],\n",
       "        [ 4.0000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train)\n",
    "x_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the predicted values using the weights \n",
    "Using final weights calculated from our training in order to get the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7720],\n",
       "        [0.9048],\n",
       "        [2.8276],\n",
       "        [2.6768],\n",
       "        [1.6212],\n",
       "        [2.9468],\n",
       "        [3.3555],\n",
       "        [1.9605],\n",
       "        [3.2386],\n",
       "        [0.7917],\n",
       "        [3.0162],\n",
       "        [3.7702],\n",
       "        [1.6966],\n",
       "        [2.2621],\n",
       "        [1.5081]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_in_tensor = x_train_tensor.mm(w1).mm(w2)\n",
    "predicted_in_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the prediction to a numpy array\n",
    "This will be used to plot the regression line in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7719933 ],\n",
       "       [0.90484774],\n",
       "       [2.827649  ],\n",
       "       [2.6768413 ],\n",
       "       [1.6211855 ],\n",
       "       [2.9467874 ],\n",
       "       [3.3554769 ],\n",
       "       [1.9605033 ],\n",
       "       [3.238601  ],\n",
       "       [0.7917418 ],\n",
       "       [3.016159  ],\n",
       "       [3.770199  ],\n",
       "       [1.6965895 ],\n",
       "       [2.2621193 ],\n",
       "       [1.5080795 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predicted_in_tensor.detach().numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "Our training has produced a rather accurate regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(x_train, y_train, label = 'Original data', s=250, c='g') \n",
    "\n",
    "plt.plot(x_train, predicted, label = 'Fitted line ')\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "n=50\n",
    "x=np.random.rand(n)\n",
    "y=x*np.random.randn(n)\n",
    "\n",
    "colors = np.random.rand(n)\n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x,y,1))(np.unique(x)))\n",
    "\n",
    "plt.scatter(x,y,c=colors,alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.748549461364746\n",
      "100 0.14980310201644897\n",
      "w_alpha Grad =  -0.3407284617424011  w_beta Grad =  -0.5186246037483215\n",
      "200 0.005887317471206188\n",
      "w_alpha Grad =  -0.06525570899248123  w_beta Grad =  -0.11431684345006943\n",
      "300 0.0002652518742252141\n",
      "w_alpha Grad =  -0.012681262567639351  w_beta Grad =  -0.02554965950548649\n",
      "400 1.2771343790518586e-05\n",
      "w_alpha Grad =  -0.002525575924664736  w_beta Grad =  -0.005741352681070566\n",
      "500 6.325632853076968e-07\n",
      "w_alpha Grad =  -0.0005171024240553379  w_beta Grad =  -0.0012920351000502706\n",
      "600 3.1774302300391355e-08\n",
      "w_alpha Grad =  -0.00010876217857003212  w_beta Grad =  -0.0002910251496359706\n",
      "700 1.6044989781249797e-09\n",
      "w_alpha Grad =  -2.3795757442712784e-05  w_beta Grad =  -6.570004188688472e-05\n",
      "800 9.764136721379657e-11\n",
      "w_alpha Grad =  -5.878973752260208e-06  w_beta Grad =  -1.5187851204245817e-05\n",
      "900 3.0997291539103244e-11\n",
      "w_alpha Grad =  -5.9497542679309845e-06  w_beta Grad =  -5.8256932788935956e-06\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 64\n",
    "\n",
    "alpha = 1.3\n",
    "beta = np.array([[1.9],[1.5]])#\n",
    "\n",
    "x_data = np.random.randn(N, 2)#\n",
    "y_data = x_data.dot(beta) + alpha\n",
    "\n",
    "x=torch.from_numpy(x_data).float()\n",
    "y=torch.from_numpy(y_data).float()\n",
    "\n",
    "w_beta = torch.randn((2, 1), requires_grad=True)\n",
    "w_alpha = torch.randn(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD([w_beta, w_alpha], lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "for t in range(1000):\n",
    "    y_pred = x.mm(w_beta).add(w_alpha)\n",
    "    \n",
    "#     loss = (y_pred - y).pow(2).sum()\n",
    "    loss = criterion(y_pred,y)\n",
    "\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "        if w_alpha.grad is not None and w_beta.grad is not None:\n",
    "            print(\"w_alpha Grad = \",w_alpha.grad[0].item(),\" w_beta Grad = \",w_beta.grad[0].item())\n",
    "    \n",
    "    optimizer.zero_grad()   \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Beta: tensor([[1.9000],\n",
      "        [1.5000]], requires_grad=True)\n",
      "Optimized Alpha: tensor([1.3000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized Beta: {0}\".format(w_beta))\n",
    "print(\"Optimized Alpha: {0}\".format(w_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.006211280822754\n",
      "500 0.004818673711270094\n",
      "1000 0.0013969732681289315\n",
      "1500 0.0002295930898981169\n",
      "2000 1.8603743228595704e-05\n",
      "2500 6.29012333774881e-07\n",
      "3000 7.020580117256259e-09\n",
      "3500 2.2144491101938613e-11\n",
      "4000 1.5726727212173053e-11\n",
      "4500 8.915463853287342e-12\n",
      "Optimized Alpha:  2.9999921321868896\n",
      "Optimized Beta:  1.0000044107437134\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SIZE=100\n",
    "torch.manual_seed(123)\n",
    "\n",
    "class DS:\n",
    "    def __init__(self,size=SIZE):\n",
    "        self.x=torch.rand(size,1)\n",
    "        self.y=torch.Tensor(size,1)\n",
    "dataset=DS()\n",
    "\n",
    "for i in range(SIZE):\n",
    "    dataset.y[i,0]=3*dataset.x[i,0]+1\n",
    "\n",
    "\n",
    "x = dataset.x\n",
    "y = dataset.y\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.lin= torch.nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model=Model()\n",
    "lr = 0.01\n",
    "loss_func=torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for t in range(5000):\n",
    "    y_pred=model(x)\n",
    "\n",
    "    loss=loss_func(y_pred,y)\n",
    "\n",
    "    if t % 500 == 0:\n",
    "        print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "print(\"Optimized Alpha: \",model.lin.weight[0].item())\n",
    "print(\"Optimized Beta: \",model.lin.bias[0].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logestic Regression\n",
    "<img src=\"logreg1.jpg\">\n",
    "<img src=\"logreg2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dataset\n",
      "[Parameter containing:\n",
      "tensor([[-0.1968,  0.0459],\n",
      "        [ 0.2205, -0.2500]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5479,  0.0048], requires_grad=True)]\n",
      "New Dataset\n",
      "Step= 0  Loss= 0.6901295185089111  Acc= 56.0\n",
      "Step= 1000  Loss= 0.15912511944770813  Acc= 97.0\n",
      "Step= 2000  Loss= 0.10199519246816635  Acc= 99.0\n",
      "Step= 3000  Loss= 0.07604885846376419  Acc= 99.0\n",
      "Step= 4000  Loss= 0.06001458689570427  Acc= 99.0\n",
      "Step= 5000  Loss= 0.048503149300813675  Acc= 100.0\n",
      "Step= 6000  Loss= 0.03951720520853996  Acc= 100.0\n",
      "Step= 7000  Loss= 0.032163333147764206  Acc= 100.0\n",
      "Step= 8000  Loss= 0.026012104004621506  Acc= 100.0\n",
      "Step= 9000  Loss= 0.020856790244579315  Acc= 100.0\n",
      "\n",
      "Optimized Alpha:  Parameter containing:\n",
      "tensor([[-37.1544, -36.4242],\n",
      "        [ 37.1780,  36.2200]], requires_grad=True)\n",
      "Optimized Beta:  Parameter containing:\n",
      "tensor([ 36.2547, -36.7978], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SIZE = 100\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "class DS:\n",
    "    def __init__(self, size=SIZE):\n",
    "        self.x = torch.rand(size, 2)\n",
    "        self.y = torch.LongTensor(size)\n",
    "        print(\"New Dataset\")\n",
    "        for i in range(SIZE):\n",
    "            if (torch.sum(self.x[i]) > 1):\n",
    "                self.y[i] = 1\n",
    "            else:\n",
    "                self.y[i] = 0\n",
    "\n",
    "\n",
    "dataset = DS()\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lin = torch.nn.Linear(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(list(model.parameters()))\n",
    "lr = 0.01\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for t in range(10000):\n",
    "    if t % 10000 == 0:\n",
    "        dataset = DS()\n",
    "    y_pred = model(dataset.x)\n",
    "\n",
    "    loss = loss_func(y_pred, dataset.y)\n",
    "    \n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "\n",
    "        predTmp = pred.type(torch.FloatTensor).clone()\n",
    "        yTmp = dataset.y.float().clone()\n",
    "        # print(predTmp)\n",
    "        # print(yTmp)\n",
    "        acc = ((predTmp.data == yTmp).sum().float() / float(len(yTmp))) * 100.\n",
    "        print(\"Step=\",t,\" Loss=\", loss.item(), \" Acc=\", acc.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print()\n",
    "print(\"Optimized Alpha: \", model.lin.weight)\n",
    "print(\"Optimized Beta: \", model.lin.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random as rand\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    avDev = torch.device(\"cpu\")\n",
    "\n",
    "print(avDev)\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    " \n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    " \n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    " \n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    " \n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    " \n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 300)\n",
    "        self.linear2 = nn.Linear(300, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    " \n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    " \n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.1999120712280273. Accuracy: 47.150001525878906\n",
      "Iteration: 1000. Loss: 2.0818870067596436. Accuracy: 62.68000030517578\n",
      "Iteration: 1500. Loss: 1.911210298538208. Accuracy: 67.51000213623047\n",
      "Iteration: 2000. Loss: 1.7680374383926392. Accuracy: 71.43000030517578\n",
      "Iteration: 2500. Loss: 1.6104234457015991. Accuracy: 74.0199966430664\n",
      "Iteration: 3000. Loss: 1.5309475660324097. Accuracy: 76.5199966430664\n",
      "Iteration: 3500. Loss: 1.3537623882293701. Accuracy: 78.05000305175781\n",
      "Iteration: 4000. Loss: 1.208117127418518. Accuracy: 79.73999786376953\n",
      "Iteration: 4500. Loss: 1.1188465356826782. Accuracy: 81.0199966430664\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    " \n",
    "model.to(avDev)\n",
    " \n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss().to(avDev)\n",
    "\n",
    " \n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    " \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         \n",
    "        #print(images.size()) #torch.Size([100, 1, 28, 28])\n",
    "        #print(images.view(-1, 28*28).size()) #torch.Size([100, 784])\n",
    "        images = images.view(-1, 28*28).to(avDev)\n",
    "        labels = labels.to(avDev)\n",
    "         \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)#\n",
    "         \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, 28*28).to(avDev)\n",
    "                 \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                 \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                 \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                 \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "             \n",
    "            accuracy = 100. * correct / total\n",
    "             \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random as rand\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES[trainset[1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "trainset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa500865fd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = trainset[1][0]\n",
    "_to_pil = transforms.ToPILImage()\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(_to_pil(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training a Logistic Regression Classifier with CIFAR-10 dataset using PyTorch\n",
    "- Draw learning curve and confusion matrix\n",
    "- Find the best hyperparameters\n",
    "- Plot gradient norm for each learnable parameter\n",
    "- Extra point:\n",
    "    - Use hyper-opt package to optimize two hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "### https://www.pluralsight.com/ (Foundation to PyTorch class)\n",
    "### Pytorch Documents\n",
    "### https://www.udemy.com/course/practical-deep-learning-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
