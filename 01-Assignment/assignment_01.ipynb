{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# General\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "test_set = dsets.MNIST(root='./data', train=False, download=True)\n",
    "train_set = dsets.MNIST(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data as numpy\n",
    "test_data = test_set.data.numpy()\n",
    "train_data = train_set.data.numpy()\n",
    "\n",
    "# Labels as numpy\n",
    "test_labels = test_set.targets.numpy()\n",
    "train_labels = train_set.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12f1a8f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sample data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = test_data[0]\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (flattened):  (10000, 784)\n",
      "Train shape (flattened):  (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Flatten train and test data\n",
    "test_flattened = test_data.reshape((test_data.shape[0], 784))\n",
    "train_flattened = train_data.reshape((train_data.shape[0], 784))\n",
    "\n",
    "print(\"Test shape (flattened): \", test_flattened.shape)\n",
    "print(\"Train shape (flattened): \", train_flattened.shape)\n",
    "\n",
    "# Extend test flattened dataset to include the bias\n",
    "test_flattened = np.hstack((test_flattened,np.ones((10000,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test labels:  (10000, 10)\n",
      "Train labels:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "one_hot_test = np.eye(CLASSES)[test_labels]\n",
    "one_hot_train = np.eye(CLASSES)[train_labels]\n",
    "\n",
    "print(\"Test labels: \", one_hot_test.shape)\n",
    "print(\"Train labels: \", one_hot_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 20\n",
    "HIDDEN = 15\n",
    "DEBUG = False\n",
    "EPSILON = 0.005\n",
    "EPOCHS = 200 * 3000 # 5 passes over data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, target,deriv = False):\n",
    "    if deriv:\n",
    "        return 2*(target - y)\n",
    "    return np.sum(np.square(target - y))\n",
    "\n",
    "# Sigmoid function for the\n",
    "# activation between input\n",
    "# and hidden layer, as well\n",
    "# as hidden to output layer\n",
    "# activation\n",
    "def sigmoid(x, deriv=False):\n",
    "    if(deriv == True):\n",
    "        return x*(1-x)\n",
    "    \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Softmax activation function\n",
    "# to normalize the output as\n",
    "# a vector of probabilities\n",
    "# for every single possible\n",
    "# class\n",
    "def softmax(x, deriv=False):\n",
    "    if(deriv == True):\n",
    "        return x*(1-x)\n",
    "\n",
    "    x = x - x.max(axis=1, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    sigma = y / y.sum(axis=1, keepdims=True)\n",
    "    return sigma\n",
    "\n",
    "# Feed forward operation\n",
    "def feed_forward(input_batch, w1, w2):\n",
    "    # Dot products\n",
    "    a1 = sigmoid(np.dot(input_batch,w1))\n",
    "    a1 = np.hstack((a1,np.ones((input_batch.shape[0],1))))\n",
    "    #print(a1.shape)\n",
    "    a2 = softmax(np.dot(a1,w2))\n",
    "    \n",
    "    return input_batch, a1, a2\n",
    "\n",
    "# Evaluate learnt weights\n",
    "def evaluate(test, w1, w2, labels):\n",
    "    # Metrics\n",
    "    corrects, wrongs = 0, 0\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    for i in range(len(test)):\n",
    "        # Add dimension\n",
    "        data = np.array([test[i]])\n",
    "        \n",
    "        # Run feedforward\n",
    "        _, _, res = feed_forward(data, w1, w2)\n",
    "        \n",
    "        # Check result\n",
    "        res_max = res.argmax()\n",
    "        if res_max == labels[i]:\n",
    "            corrects += 1\n",
    "        else:\n",
    "            wrongs += 1\n",
    "            \n",
    "    return corrects, wrongs\n",
    "\n",
    "def confusion_matrix(test_data, w1, w2, labels):\n",
    "        # Confusion matrix\n",
    "        cm = np.zeros((10, 10), int)\n",
    "        \n",
    "        for i in range(len(test_data)):\n",
    "            # Test sample\n",
    "            data = np.array([test_data[i]])\n",
    "            \n",
    "            # Get result\n",
    "            _, _, res = feed_forward(data, w1, w2)\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i]\n",
    "            cm[res_max, int(target)] += 1\n",
    "            \n",
    "        return cm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  18.69965245733769\n",
      "MSE:  11.824162153357367\n",
      "MSE:  7.332570112496555\n",
      "MSE:  5.085122774456567\n",
      "MSE:  7.4516975887444135\n",
      "MSE:  5.333856386716547\n",
      "MSE:  4.092602348595648\n",
      "MSE:  5.835051937785297\n",
      "MSE:  5.422307117828904\n",
      "MSE:  1.920589191559697\n",
      "MSE:  5.3847674910890415\n",
      "MSE:  3.5777105622243766\n",
      "MSE:  1.8300644305921057\n",
      "MSE:  5.441772049476711\n",
      "MSE:  5.321014577524788\n",
      "MSE:  1.3998511493675068\n",
      "MSE:  7.2740959349329355\n",
      "MSE:  3.4910106924420994\n",
      "MSE:  2.4117636237027975\n",
      "MSE:  7.247346106403179\n",
      "MSE:  4.03965497618214\n",
      "MSE:  3.6486487413532225\n",
      "MSE:  6.104541250937869\n",
      "MSE:  3.525020895268359\n",
      "MSE:  0.7435146673488878\n",
      "MSE:  7.028462027213054\n",
      "MSE:  5.625381717493946\n",
      "MSE:  0.6400832349695349\n",
      "MSE:  6.121722331003082\n",
      "MSE:  3.3728577729784757\n",
      "MSE:  1.7631003751558143\n",
      "MSE:  4.846129580485353\n",
      "MSE:  4.534481478245169\n",
      "MSE:  1.9016910381498706\n",
      "MSE:  6.7155367235845524\n",
      "MSE:  3.378454981990907\n",
      "MSE:  4.178673627795951\n",
      "MSE:  3.2241684528110266\n",
      "MSE:  3.6914683885516126\n",
      "MSE:  0.7930271751041436\n",
      "MSE:  2.918706144536654\n",
      "MSE:  2.5095202797740974\n",
      "MSE:  1.8298347787450975\n",
      "MSE:  5.522860441005469\n",
      "MSE:  2.1430226822937954\n",
      "MSE:  2.138131600258135\n",
      "MSE:  6.361310390100806\n",
      "MSE:  3.6655561146270337\n",
      "MSE:  3.781098120155166\n",
      "MSE:  6.842019700251716\n",
      "MSE:  2.5869117381210316\n",
      "MSE:  3.6689593111776886\n",
      "MSE:  6.851424956629141\n",
      "MSE:  3.5904744018323154\n",
      "MSE:  2.244058477500065\n",
      "MSE:  6.493557825032299\n",
      "MSE:  3.9057487780742974\n",
      "MSE:  2.244527004995876\n",
      "MSE:  5.72098316857328\n",
      "MSE:  3.6268152453260756\n"
     ]
    }
   ],
   "source": [
    "# Fix random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Weights\n",
    "w1 = 2 * np.random.random((784, HIDDEN)) - 1\n",
    "w2 = 2 * np.random.random((HIDDEN, 10)) - 1\n",
    "# Biases\n",
    "b0 = np.zeros((1,HIDDEN))\n",
    "b1 = np.zeros((1,10))\n",
    "\n",
    "\n",
    "# Biases with weights \n",
    "w1 = np.vstack((w1,b0))\n",
    "w2 = np.vstack((w2,b1))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Index\n",
    "    idx = epoch % 3000\n",
    "    \n",
    "    # Feed forward process\n",
    "    input_batch = train_flattened[(idx * BATCH):((idx + 1) * BATCH), :]\n",
    "    input_batch = np.hstack((input_batch,np.ones((20,1))))\n",
    "    #print(input_batch.shape) \n",
    "    a0, a1, a2 = feed_forward(input_batch, w1, w2)\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"A0 shape: \", a0.shape)\n",
    "        print(\"A1 shape: \", a1.shape)\n",
    "        print(\"A2 shape: \", a2.shape)\n",
    "    \n",
    "    # Compute mean error\n",
    "    y = one_hot_train[(idx * BATCH):((idx + 1) * BATCH), :]\n",
    "    \n",
    "    # Print MSE\n",
    "    if (epoch % 10000) == 0:\n",
    "        print(\"MSE: \", mse(a2,y))\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"Error shape: \", error)\n",
    "        \n",
    "    # Compute DELTA2\n",
    "    delta2 = (a2 - y) * softmax(a2, True)\n",
    "    \n",
    "    # Compute dw2\n",
    "    dw2 = np.dot(a1.T, delta2)\n",
    "    \n",
    "    \n",
    "    # Compute DELTA1\n",
    "    delta1 = np.dot(delta2, w2.T) * sigmoid(a1, True)\n",
    "    \n",
    "    dw1 = np.dot(a0.T, delta1[:,0:-1])\n",
    "    #print(\"dw2 shape\",dw1.shape)\n",
    "    \n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"DELTA2 shape: \", delta2.shape)\n",
    "        print(\"dW2 shape: \", dw2.shape)\n",
    "        print(\"DELTA1 shape: \", delta1.shape)\n",
    "        print(\"dW1 shape: \", dw1.shape)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Update weights\n",
    "    w2 -= (EPSILON * dw2)\n",
    "    w1 -= (EPSILON * dw1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "c, w = evaluate(test_flattened, w1, w2, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracay is:  0.8906\n"
     ]
    }
   ],
   "source": [
    "print(\"The model accuracay is: \", c / (c + w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_flattened, w1, w2, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 917,    0,   10,    2,    0,   24,   17,    5,   13,    2],\n",
       "       [   0, 1072,    3,    1,    5,    7,    3,   14,    4,    6],\n",
       "       [   5,    2,  873,   20,    6,    8,   11,   24,   14,    2],\n",
       "       [   4,   16,   42,  910,    2,   46,    0,    5,   33,   13],\n",
       "       [   4,    0,   20,    1,  866,   11,    7,    4,   14,   28],\n",
       "       [   8,    2,    8,   38,    3,  723,    6,    0,   11,   19],\n",
       "       [  18,    2,   17,    2,   17,   22,  890,    1,   17,    7],\n",
       "       [   4,   22,   12,   13,    1,    2,    1,  932,   14,   42],\n",
       "       [  11,   19,   45,   18,   10,   42,   16,    7,  841,    8],\n",
       "       [   9,    0,    2,    5,   72,    7,    7,   36,   13,  882]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
