{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment3 (3).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "25bkpNjSIzF3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmnCYancGUuw",
        "outputId": "7fcf30d3-da36-4742-b3ea-05a0d7eef222"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import random as rand\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "torch.manual_seed(24)    \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa192815b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwA-Nbb2GUux",
        "outputId": "31698487-39e3-4485-b852-04d5ca0b6915"
      },
      "source": [
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "dataset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIRPaHvTGUux",
        "outputId": "3410bf40-8c74-4dc3-d6a7-1e639ed3a7cb"
      },
      "source": [
        "'''\n",
        "STEP 2: SPLIT DATA TO TRAINING AND VALIDATION\n",
        "'''\n",
        "#validation set size 5000 \n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "#creating training & validation set using random_split\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "len(train_dataset), len(val_dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bGGAbsOGUux"
      },
      "source": [
        "'''\n",
        "STEP 3: MAKING DATASET ITERABLE\n",
        "'''\n",
        "#Creating data loader to load data in batches\n",
        "batch_size=124\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YqVaFruGUux"
      },
      "source": [
        "'''\n",
        "Step 4 : Creat Model class\n",
        "'''\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class CIFAR10Model(nn.Module):\n",
        "    def __init__(self,activation_function):\n",
        "        super().__init__()\n",
        "        # hidden layer\n",
        "        self.linear1 = nn.Linear(input_size, 1536)\n",
        "        self.linear1_drop = nn.Dropout(0.2)\n",
        "        self.linear2 = nn.Linear(1536, 768)\n",
        "        self.linear2_drop = nn.Dropout(0.2)\n",
        "        self.linear3 = nn.Linear(768, 576)\n",
        "        self.linear3_drop = nn.Dropout(0.1)\n",
        "        # output layer\n",
        "        self.linear4 = nn.Linear(576, output_size)\n",
        "        self.activation_function=activation_function\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Flatten images into vectors\n",
        "        out = x.view(x.size(0), -1)\n",
        "        # Apply layers & activation functions\n",
        "        out = self.linear1(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear1_drop(out)\n",
        "\n",
        "        out = self.linear2(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear2_drop(out)\n",
        "        \n",
        "        out = self.linear3(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear3_drop(out)\n",
        "        # Get predictions using output layer\n",
        "        out = self.linear4(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = torch.nn.functional.cross_entropy(out, labels)\n",
        "        #print(loss)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = torch.nn.functional.cross_entropy(out, labels)(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "\n",
        "input_size = 3*32*32\n",
        "output_size = 10\n",
        "model = CIFAR10Model(\"tanh\")\n",
        "log_interval=100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YWcYvpGUux"
      },
      "source": [
        "lambda2 = 0.001 # regularization hyperparameters\n",
        "lambda1 = 0\n",
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "# we train with l1 and l2 regularization\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch_idx,batch in enumerate(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            l2_regularization = 0\n",
        "            l1_regularization = 0\n",
        "            for param in model.parameters():\n",
        "              l2_regularization += torch.norm(param)**2\n",
        "              l1_regularization += torch.sum(torch.abs(param))\n",
        "\n",
        "            loss = loss + lambda2*l2_regularization + lambda1*l1_regularization\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            #if batch_idx % log_interval == 0:\n",
        "            #    print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
        "            #        epoch, batch_idx * len(batch[0]), len(train_dataset),\n",
        "            #        loss.item()))\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4t8_0vsGUux"
      },
      "source": [
        "'''\n",
        "Step 5: Move model and data to GPU if availble \n",
        "'''\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "    \n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)\n",
        "\n",
        "model = to_device(model, device)\n",
        "l2_regularization = torch.tensor(0)\n",
        "l2_regularization = to_device(l2_regularization, device).float()\n",
        "l1_regularization = torch.tensor(0)\n",
        "l1_regularization = to_device(l1_regularization, device).float()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJMyU1vZGUux",
        "outputId": "474dea5f-1725-4a72-9a73-c691f975df6d"
      },
      "source": [
        "'''\n",
        "Step 5: Train Model\n",
        "'''\n",
        "history = [evaluate(model, val_loader)]\n",
        "history # initial Loss and accuracy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.12012289464473724, 'val_loss': -2.305201530456543}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUkhAYGUuy"
      },
      "source": [
        "#history += fit(10, 0.05, model, train_loader, val_loader)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1x5etBbXxqF"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1W4KZIXwo8"
      },
      "source": [
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X6aIEmhGUuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c00eb2-758a-4479-e42e-122d5db25d46"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#RMSProp and tanh = {'val_acc': 0.09674469381570816, 'val_loss': 37.956207275390625}\n",
        "#RMSProp and sigmoid {'val_acc': 0.10073761641979218, 'val_loss': 21.830883026123047}\n",
        "#RMSProp and relu {'val_acc': 0.0991738811135292, 'val_loss': 2.3054039478302}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.RMSprop)\n",
        "plot_losses(history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: -5718777129609461760.0000, val_acc: 0.1040\n",
            "Epoch [1], val_loss: -36129360551463616512.0000, val_acc: 0.1040\n",
            "Epoch [2], val_loss: -115215378160786866176.0000, val_acc: 0.1040\n",
            "Epoch [3], val_loss: -273137740677044502528.0000, val_acc: 0.1040\n",
            "Epoch [4], val_loss: -547364930251447599104.0000, val_acc: 0.1040\n",
            "Epoch [5], val_loss: -984244528588242550784.0000, val_acc: 0.1040\n",
            "Epoch [6], val_loss: -1641031483845446205440.0000, val_acc: 0.1040\n",
            "Epoch [7], val_loss: -2586741525172046528512.0000, val_acc: 0.1040\n",
            "Epoch [8], val_loss: -3894512266091610243072.0000, val_acc: 0.1040\n",
            "Epoch [9], val_loss: -5633515619180827639808.0000, val_acc: 0.1040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0FN-SP2cZWG"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-0ixo5icY3P"
      },
      "source": [
        "evaluate(model, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25JXZZ0JGUuy"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adadelta and tanh {'val_acc': 0.4410897195339203, 'val_loss': 1.5692006349563599}\n",
        "#Adadelta and sigmoid {'val_acc': 0.18444138765335083, 'val_loss': 2.0757439136505127}\n",
        "#Adadelta and relu {'val_acc': 0.495879203081131, 'val_loss': 1.4351319074630737}\n",
        "\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adadelta)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7DjM_R5ci-5"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA0Vo17rci1H"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7j70F3GGUuy"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adagrad and tanh {'val_acc': 0.2304287850856781, 'val_loss': 2.1180825233459473}\n",
        "#Adagrad and sigmoid {'val_acc': 0.0991738811135292, 'val_loss': 2.3229012489318848}\n",
        "#Adagrad and relu {'val_acc': 0.38202202320098877, 'val_loss': 1.717851161956787}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adagrad)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUHSGRp1cozY"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpE6zGfLcr8D"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Gn5aewGUu2"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adam and tanh {'val_acc': 0.09625294804573059, 'val_loss': 12.214295387268066}\n",
        "#Adam and sigmoid {'val_acc': 0.10023604333400726, 'val_loss': 2.4134914875030518}\n",
        "#Adam and relu {'val_acc': 0.10160306841135025, 'val_loss': 2086.643310546875}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adam)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCFRNB2Wc0jq"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmT6W-T7c0Tz"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jugQrquTGUu2"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#SGD and tanh {'val_acc': 0.4307238459587097, 'val_loss': 1.5837513208389282}\n",
        "#SGD and sigmoid {'val_acc': 0.16859754920005798, 'val_loss': 2.1040098667144775}\n",
        "#SGD and relu {'val_acc': 0.46284419298171997, 'val_loss': 1.4877265691757202}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.SGD)\n",
        "plot_losses(history)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlGQPK5qc5lD"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpqZPoPqc5Y0"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgSKeqM1GUu2"
      },
      "source": [
        "# best model found was \n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adadelta)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnvzZpszGUu2"
      },
      "source": [
        "\"\"\"\n",
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "    \n",
        "plot_losses(history)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMA97ciXGUu2"
      },
      "source": [
        "\"\"\"\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "    \n",
        "plot_accuracies(history)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XjyZuE8GUu2"
      },
      "source": [
        "evaluate(model, test_loader) # its displayed as validation loss and accuracy, but this is the test loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqvcEkYKzWDp"
      },
      "source": [
        "###Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QofMApb3zVPI"
      },
      "source": [
        "import numpy as np\n",
        "cm = np.zeros((10, 10), int)\n",
        "model = to_device(model, \"cpu\")\n",
        "for i in range(len(test_dataset)):\n",
        "  data = test_dataset[i][0]\n",
        "  label = test_dataset[i][1]\n",
        "  data = data.view(1,data.shape[0],data.shape[1],data.shape[2])\n",
        "  predict = model.forward(data)\n",
        "  target = label\n",
        "  cm[predict.argmax(), target] += 1\n",
        "print(cm)\n",
        "    #print(data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25bkpNjSIzF3"
      },
      "source": [
        "### Hyper Parameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awYBftOpI5aH"
      },
      "source": [
        "\"\"\"\n",
        "from hyperopt import hp, tpe, fmin\n",
        "def run_model(learning_rate):\n",
        "  model = CIFAR10Model()\n",
        "  model = to_device(model, device)\n",
        "  error = fit(1, learning_rate, model, train_loader, val_loader)\n",
        "  return error[-1][\"val_loss\"]\n",
        "\n",
        "\n",
        "best = fmin(fn=lambda x: run_model(x),\n",
        "            space=hp.uniform('x', 0.01, 1),\n",
        "            algo=tpe.suggest, \n",
        "            max_evals=100)\n",
        "print(\"Best Learning Rate\",best)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibXP4GouOS8w"
      },
      "source": [
        "\"\"\"\n",
        "def run_model(batch_size):\n",
        "  model = CIFAR10Model()\n",
        "  batch_size=batch_size\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "  train_loader = DeviceDataLoader(train_loader, device)\n",
        "  val_loader = DeviceDataLoader(val_loader, device)\n",
        "  test_loader = DeviceDataLoader(test_loader, device)\n",
        "  model = to_device(model, device)\n",
        "  error = fit(1, 0.06, model, train_loader, val_loader)\n",
        "  return error[-1][\"val_loss\"]\n",
        "\n",
        "\n",
        "best = fmin(fn=lambda x: run_model(x),\n",
        "            space=hp.choice('x',[1,32,64,124,256,512,1024]),\n",
        "            algo=tpe.suggest, \n",
        "            max_evals=10)\n",
        "print(\"Best Batch Size\",best)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}