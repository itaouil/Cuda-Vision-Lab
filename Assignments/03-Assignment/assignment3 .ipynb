{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmnCYancGUuw",
    "outputId": "6f3a0233-89c2-4bc0-eea9-ca66213672f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x104851228>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Python\n",
    "import random as rand\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Seeding\n",
    "torch.manual_seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU/GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwA-Nbb2GUux",
    "outputId": "867a32a6-aaed-48b6-986b-c9d1196becdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2948553fa604054b58198aa39453b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "batch_size=124\n",
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIRPaHvTGUux",
    "outputId": "81bb9618-22d4-40ec-f396-e3f3398f4ca0"
   },
   "outputs": [],
   "source": [
    "# Create train and validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set lenght:  5000\n",
      "Train set length:  45000\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set lenght: \", len(val_dataset))\n",
    "print(\"Train set length: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7bGGAbsOGUux"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move dataloader to device\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3*32*32\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8YqVaFruGUux"
   },
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "    \n",
    "def my_cross_entropy(x, y):\n",
    "    prob = x.log_softmax(1)\n",
    "    log_prob = -1.0 * prob\n",
    "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "# Accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "# Training\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training Phase \n",
    "        for batch_idx,batch in enumerate(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            l2_regularization = 0\n",
    "            l1_regularization = 0\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param)**2\n",
    "                l1_regularization += torch.sum(torch.abs(param))\n",
    "\n",
    "            loss = loss + lambda2 * l2_regularization + lambda1 * l1_regularization\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(epoch, \n",
    "                                                                     batch_idx * len(batch[0]),\n",
    "                                                                     len(train_dataset),\n",
    "                                                                     loss.item()))\n",
    "                \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self, function):\n",
    "        # Init\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set activation function\n",
    "        self.function = function\n",
    "        \n",
    "        # 1st hidden layer\n",
    "        self.linear1 = nn.Linear(input_size, 1536)\n",
    "        self.linear1_drop = nn.Dropout(0.2)\n",
    "        \n",
    "        # 2nd hidden layer\n",
    "        self.linear2 = nn.Linear(1536, 768)\n",
    "        self.linear2_drop = nn.Dropout(0.2)\n",
    "        \n",
    "        # 3rd hidden layer\n",
    "        self.linear3 = nn.Linear(768, 576)\n",
    "        self.linear3_drop = nn.Dropout(0.1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.linear4 = nn.Linear(576, output_size)\n",
    "    \n",
    "    def activation(self, input_):\n",
    "        # Output after activation\n",
    "        output = None\n",
    "        \n",
    "        # Apply activation function\n",
    "        if self.function == \"relu\":\n",
    "            output = torch.nn.functional.relu(input_)\n",
    "        if self.function == \"tanh\":\n",
    "            output = torch.nn.functional.tanh(input_)\n",
    "        if self.function == \"sigmoid\":\n",
    "            output = torch.nn.functional.sigmoid(input_)\n",
    "        \n",
    "        return output        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten images into vectors\n",
    "        out = x.view(x.size(0), -1)\n",
    "                \n",
    "        # 1st layer propagation\n",
    "        out = self.activation(self.linear1(out))\n",
    "        out = self.linear1_drop(out)\n",
    "                \n",
    "        # 2nd layer propagation\n",
    "        out = self.activation(self.linear2(out))\n",
    "        out = self.linear2_drop(out)\n",
    "        \n",
    "        # 3rd layer propagation\n",
    "        out = self.activation(self.linear3(out))\n",
    "        out = self.linear3_drop(out)\n",
    "        \n",
    "        # Get predictions using output layer\n",
    "        out = self.linear4(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        # Unpack batch\n",
    "        images, labels = batch\n",
    "        \n",
    "        # Run forward pass\n",
    "        out = self.forward(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = my_cross_entropy(out, labels)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #Â Unpack batch\n",
    "        images, labels = batch\n",
    "        \n",
    "        #Â Run forward pass\n",
    "        out = self.forward(images)\n",
    "        #torch.nn.functional.cross_entropy (out, labels)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = my_cross_entropy(out, labels)\n",
    "        \n",
    "        #Â Compute accuracy\n",
    "        acc = accuracy(out, labels)\n",
    "        \n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(losses, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization\n",
    "lambda1 = 0\n",
    "lambda2 = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD + tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "4X6aIEmhGUuy",
    "outputId": "ecff0568-f69a-4d86-a926-4d6037eeccf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/45000]\tLoss: 3.250338\n",
      "Train Epoch: 0 [12400/45000]\tLoss: 2.898279\n",
      "Train Epoch: 0 [24800/45000]\tLoss: 2.838905\n",
      "Train Epoch: 0 [37200/45000]\tLoss: 2.583334\n",
      "Epoch [0], val_loss: 1.8463, val_acc: 0.3476\n",
      "Train Epoch: 1 [0/45000]\tLoss: 2.647557\n",
      "Train Epoch: 1 [12400/45000]\tLoss: 2.811702\n",
      "Train Epoch: 1 [24800/45000]\tLoss: 2.777201\n",
      "Train Epoch: 1 [37200/45000]\tLoss: 2.781892\n",
      "Epoch [1], val_loss: 1.7857, val_acc: 0.3831\n",
      "Train Epoch: 2 [0/45000]\tLoss: 2.784484\n",
      "Train Epoch: 2 [12400/45000]\tLoss: 2.612975\n",
      "Train Epoch: 2 [24800/45000]\tLoss: 2.714663\n",
      "Train Epoch: 2 [37200/45000]\tLoss: 2.521603\n",
      "Epoch [2], val_loss: 1.9199, val_acc: 0.2876\n",
      "Train Epoch: 3 [0/45000]\tLoss: 2.706659\n",
      "Train Epoch: 3 [12400/45000]\tLoss: 2.521517\n",
      "Train Epoch: 3 [24800/45000]\tLoss: 2.645594\n",
      "Train Epoch: 3 [37200/45000]\tLoss: 2.512980\n",
      "Epoch [3], val_loss: 1.7971, val_acc: 0.3565\n",
      "Train Epoch: 4 [0/45000]\tLoss: 2.546398\n",
      "Train Epoch: 4 [12400/45000]\tLoss: 2.368983\n",
      "Train Epoch: 4 [24800/45000]\tLoss: 2.491840\n",
      "Train Epoch: 4 [37200/45000]\tLoss: 2.373120\n",
      "Epoch [4], val_loss: 1.7469, val_acc: 0.3810\n",
      "Train Epoch: 5 [0/45000]\tLoss: 2.416752\n",
      "Train Epoch: 5 [12400/45000]\tLoss: 2.512420\n",
      "Train Epoch: 5 [24800/45000]\tLoss: 2.404391\n",
      "Train Epoch: 5 [37200/45000]\tLoss: 2.364686\n",
      "Epoch [5], val_loss: 1.7258, val_acc: 0.4050\n",
      "Train Epoch: 6 [0/45000]\tLoss: 2.408072\n",
      "Train Epoch: 6 [12400/45000]\tLoss: 2.305818\n",
      "Train Epoch: 6 [24800/45000]\tLoss: 2.426570\n",
      "Train Epoch: 6 [37200/45000]\tLoss: 2.490578\n",
      "Epoch [6], val_loss: 1.7240, val_acc: 0.4027\n",
      "Train Epoch: 7 [0/45000]\tLoss: 2.444210\n",
      "Train Epoch: 7 [12400/45000]\tLoss: 2.215051\n",
      "Train Epoch: 7 [24800/45000]\tLoss: 2.271785\n",
      "Train Epoch: 7 [37200/45000]\tLoss: 2.329554\n",
      "Epoch [7], val_loss: 1.6826, val_acc: 0.3961\n",
      "Train Epoch: 8 [0/45000]\tLoss: 2.219366\n",
      "Train Epoch: 8 [12400/45000]\tLoss: 2.453827\n",
      "Train Epoch: 8 [24800/45000]\tLoss: 2.424700\n",
      "Train Epoch: 8 [37200/45000]\tLoss: 2.091232\n",
      "Epoch [8], val_loss: 1.7268, val_acc: 0.3741\n",
      "Train Epoch: 9 [0/45000]\tLoss: 2.077202\n",
      "Train Epoch: 9 [12400/45000]\tLoss: 1.980067\n",
      "Train Epoch: 9 [24800/45000]\tLoss: 2.044066\n",
      "Train Epoch: 9 [37200/45000]\tLoss: 2.156325\n",
      "Epoch [9], val_loss: 1.6457, val_acc: 0.4170\n",
      "Train Epoch: 10 [0/45000]\tLoss: 1.886919\n",
      "Train Epoch: 10 [12400/45000]\tLoss: 2.066556\n",
      "Train Epoch: 10 [24800/45000]\tLoss: 2.145214\n",
      "Train Epoch: 10 [37200/45000]\tLoss: 2.191427\n",
      "Epoch [10], val_loss: 1.6559, val_acc: 0.4106\n",
      "Train Epoch: 11 [0/45000]\tLoss: 2.142987\n",
      "Train Epoch: 11 [12400/45000]\tLoss: 2.127871\n",
      "Train Epoch: 11 [24800/45000]\tLoss: 2.084515\n",
      "Train Epoch: 11 [37200/45000]\tLoss: 2.139190\n",
      "Epoch [11], val_loss: 1.6325, val_acc: 0.4177\n",
      "Train Epoch: 12 [0/45000]\tLoss: 2.049896\n",
      "Train Epoch: 12 [12400/45000]\tLoss: 2.095333\n",
      "Train Epoch: 12 [24800/45000]\tLoss: 1.907633\n",
      "Train Epoch: 12 [37200/45000]\tLoss: 2.180578\n",
      "Epoch [12], val_loss: 1.6716, val_acc: 0.3965\n",
      "Train Epoch: 13 [0/45000]\tLoss: 1.946908\n",
      "Train Epoch: 13 [12400/45000]\tLoss: 2.130435\n",
      "Train Epoch: 13 [24800/45000]\tLoss: 1.949844\n",
      "Train Epoch: 13 [37200/45000]\tLoss: 1.984640\n",
      "Epoch [13], val_loss: 1.6096, val_acc: 0.4252\n",
      "Train Epoch: 14 [0/45000]\tLoss: 2.113230\n",
      "Train Epoch: 14 [12400/45000]\tLoss: 1.807895\n",
      "Train Epoch: 14 [24800/45000]\tLoss: 1.987042\n",
      "Train Epoch: 14 [37200/45000]\tLoss: 1.995784\n",
      "Epoch [14], val_loss: 1.5950, val_acc: 0.4308\n",
      "Train Epoch: 15 [0/45000]\tLoss: 2.039461\n",
      "Train Epoch: 15 [12400/45000]\tLoss: 1.843159\n",
      "Train Epoch: 15 [24800/45000]\tLoss: 2.044338\n",
      "Train Epoch: 15 [37200/45000]\tLoss: 1.902861\n",
      "Epoch [15], val_loss: 1.5932, val_acc: 0.4387\n",
      "Train Epoch: 16 [0/45000]\tLoss: 2.036091\n",
      "Train Epoch: 16 [12400/45000]\tLoss: 1.871552\n",
      "Train Epoch: 16 [24800/45000]\tLoss: 1.882273\n",
      "Train Epoch: 16 [37200/45000]\tLoss: 1.976525\n",
      "Epoch [16], val_loss: 1.5812, val_acc: 0.4449\n",
      "Train Epoch: 17 [0/45000]\tLoss: 1.906158\n",
      "Train Epoch: 17 [12400/45000]\tLoss: 1.947492\n",
      "Train Epoch: 17 [24800/45000]\tLoss: 1.753331\n",
      "Train Epoch: 17 [37200/45000]\tLoss: 1.929282\n",
      "Epoch [17], val_loss: 1.5649, val_acc: 0.4449\n",
      "Train Epoch: 18 [0/45000]\tLoss: 1.822005\n",
      "Train Epoch: 18 [12400/45000]\tLoss: 1.838326\n",
      "Train Epoch: 18 [24800/45000]\tLoss: 1.768088\n",
      "Train Epoch: 18 [37200/45000]\tLoss: 1.744312\n",
      "Epoch [18], val_loss: 1.5749, val_acc: 0.4424\n",
      "Train Epoch: 19 [0/45000]\tLoss: 1.841318\n",
      "Train Epoch: 19 [12400/45000]\tLoss: 1.871872\n",
      "Train Epoch: 19 [24800/45000]\tLoss: 1.807412\n",
      "Train Epoch: 19 [37200/45000]\tLoss: 2.028830\n",
      "Epoch [19], val_loss: 1.6134, val_acc: 0.4289\n",
      "Train Epoch: 20 [0/45000]\tLoss: 1.901281\n",
      "Train Epoch: 20 [12400/45000]\tLoss: 1.826505\n",
      "Train Epoch: 20 [24800/45000]\tLoss: 1.806197\n",
      "Train Epoch: 20 [37200/45000]\tLoss: 1.806742\n",
      "Epoch [20], val_loss: 1.6097, val_acc: 0.4267\n",
      "Train Epoch: 21 [0/45000]\tLoss: 1.824301\n",
      "Train Epoch: 21 [12400/45000]\tLoss: 1.685536\n",
      "Train Epoch: 21 [24800/45000]\tLoss: 2.053615\n",
      "Train Epoch: 21 [37200/45000]\tLoss: 1.947077\n",
      "Epoch [21], val_loss: 1.5538, val_acc: 0.4495\n",
      "Train Epoch: 22 [0/45000]\tLoss: 1.826792\n",
      "Train Epoch: 22 [12400/45000]\tLoss: 1.816886\n",
      "Train Epoch: 22 [24800/45000]\tLoss: 1.695413\n",
      "Train Epoch: 22 [37200/45000]\tLoss: 1.710973\n",
      "Epoch [22], val_loss: 1.5983, val_acc: 0.4378\n",
      "Train Epoch: 23 [0/45000]\tLoss: 1.968081\n",
      "Train Epoch: 23 [12400/45000]\tLoss: 1.690332\n",
      "Train Epoch: 23 [24800/45000]\tLoss: 1.835982\n",
      "Train Epoch: 23 [37200/45000]\tLoss: 1.794467\n",
      "Epoch [23], val_loss: 1.5708, val_acc: 0.4409\n",
      "Train Epoch: 24 [0/45000]\tLoss: 1.817204\n",
      "Train Epoch: 24 [12400/45000]\tLoss: 1.695049\n",
      "Train Epoch: 24 [24800/45000]\tLoss: 1.695708\n",
      "Train Epoch: 24 [37200/45000]\tLoss: 1.799294\n",
      "Epoch [24], val_loss: 1.6239, val_acc: 0.4222\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Â Model\n",
    "model = CIFAR10Model(\"tanh\")\n",
    "model = to_device(model, device)\n",
    "\n",
    "# Train\n",
    "history_sgd_tanh = fit(25, 0.06, model, train_loader, val_loader, opt_func=torch.optim.SGD)\n",
    "\n",
    "# Save\n",
    "torch.save(model, \"sgd_tanh.th\")\n",
    "\n",
    "#Â Plot\n",
    "plot_losses(history_sgd_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "V-0ixo5icY3P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.6628268957138062, 'val_acc': 0.405015766620636}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adadelta + tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "25JXZZ0JGUuy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/45000]\tLoss: 3.271164\n",
      "Train Epoch: 0 [12400/45000]\tLoss: 2.993495\n",
      "Train Epoch: 0 [24800/45000]\tLoss: 2.806086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-4abe8612e7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory_adadelta_tanh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.06\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-13d827bdf4f0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml2_regularization\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dailand10/opt/miniconda3/envs/cvl/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# history = [evaluate(model, val_loader)]\n",
    "# #Adadelta and tanh {'val_acc': 0.4410897195339203, 'val_loss': 1.5692006349563599}\n",
    "# #Adadelta and sigmoid {'val_acc': 0.18444138765335083, 'val_loss': 2.0757439136505127}\n",
    "# #Adadelta and relu {'val_acc': 0.495879203081131, 'val_loss': 1.4351319074630737}\n",
    "\n",
    "#Â Model\n",
    "model = CIFAR10Model(\"tanh\")\n",
    "model = to_device(model, device)\n",
    "\n",
    "# Train\n",
    "history_adadelta_tanh = fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adadelta)\n",
    "\n",
    "# Save\n",
    "torch.save(model, \"adadelta_tanh.th\")\n",
    "\n",
    "#Â Plot\n",
    "plot_losses(history_adadelta_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA0Vo17rci1H"
   },
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad + tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7j70F3GGUuy"
   },
   "outputs": [],
   "source": [
    "# history = [evaluate(model, val_loader)]\n",
    "# #Adagrad and tanh {'val_acc': 0.2304287850856781, 'val_loss': 2.1180825233459473}\n",
    "# #Adagrad and sigmoid {'val_acc': 0.0991738811135292, 'val_loss': 2.3229012489318848}\n",
    "# #Adagrad and relu {'val_acc': 0.38202202320098877, 'val_loss': 1.717851161956787}\n",
    "\n",
    "\n",
    "model = CIFAR10Model(\"relu\")\n",
    "model = to_device(model, device)\n",
    "\n",
    "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adagrad)\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUHSGRp1cozY"
   },
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpE6zGfLcr8D"
   },
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-Gn5aewGUu2"
   },
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "#Adam and tanh {'val_acc': 0.09625294804573059, 'val_loss': 12.214295387268066}\n",
    "#Adam and sigmoid {'val_acc': 0.10023604333400726, 'val_loss': 2.4134914875030518}\n",
    "#Adam and relu {'val_acc': 0.10160306841135025, 'val_loss': 2086.643310546875}\n",
    "model = CIFAR10Model(\"relu\")\n",
    "model = to_device(model, device)\n",
    "\n",
    "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adam)\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCFRNB2Wc0jq"
   },
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmT6W-T7c0Tz"
   },
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jugQrquTGUu2"
   },
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "#SGD and tanh {'val_acc': 0.4307238459587097, 'val_loss': 1.5837513208389282}\n",
    "#SGD and sigmoid {'val_acc': 0.16859754920005798, 'val_loss': 2.1040098667144775}\n",
    "#SGD and relu {'val_acc': 0.46284419298171997, 'val_loss': 1.4877265691757202}\n",
    "model = CIFAR10Model(\"relu\")\n",
    "model = to_device(model, device)\n",
    "\n",
    "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.SGD)\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqvcEkYKzWDp"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QofMApb3zVPI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db62bf2a324f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_device' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cm = np.zeros((10, 10), int)\n",
    "model = to_device(model, \"cpu\")\n",
    "for i in range(len(test_dataset)):\n",
    "    data = test_dataset[i][0]\n",
    "    label = test_dataset[i][1]\n",
    "    data = data.view(1,data.shape[0],data.shape[1],data.shape[2])\n",
    "    predict = model.forward(data)\n",
    "    target = label\n",
    "    cm[predict.argmax(), target] += 1\n",
    "\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "25bkpNjSIzF3"
   ],
   "name": "assignment3 (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
