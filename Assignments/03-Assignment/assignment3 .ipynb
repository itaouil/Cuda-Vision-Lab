{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment3 (3).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "25bkpNjSIzF3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmnCYancGUuw",
        "outputId": "6f3a0233-89c2-4bc0-eea9-ca66213672f3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import random as rand\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "torch.manual_seed(24)    \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f774a557b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwA-Nbb2GUux",
        "outputId": "867a32a6-aaed-48b6-986b-c9d1196becdb"
      },
      "source": [
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "dataset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIRPaHvTGUux",
        "outputId": "81bb9618-22d4-40ec-f396-e3f3398f4ca0"
      },
      "source": [
        "'''\n",
        "STEP 2: SPLIT DATA TO TRAINING AND VALIDATION\n",
        "'''\n",
        "#validation set size 5000 \n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "#creating training & validation set using random_split\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "len(train_dataset), len(val_dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bGGAbsOGUux"
      },
      "source": [
        "'''\n",
        "STEP 3: MAKING DATASET ITERABLE\n",
        "'''\n",
        "#Creating data loader to load data in batches\n",
        "batch_size=124\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YqVaFruGUux"
      },
      "source": [
        "'''\n",
        "Step 4 : Creat Model class\n",
        "'''\n",
        "def log_softmax(x): # this should be applied across dim = 1\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "    \n",
        "def my_cross_entropy(x, y):\n",
        "    prob = x.log_softmax(1)\n",
        "    log_prob = -1.0 * prob\n",
        "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class CIFAR10Model(nn.Module):\n",
        "    def __init__(self,activation_function):\n",
        "        super().__init__()\n",
        "        # hidden layer\n",
        "        self.linear1 = nn.Linear(input_size, 1536)\n",
        "        self.linear1_drop = nn.Dropout(0.2)\n",
        "        self.linear2 = nn.Linear(1536, 768)\n",
        "        self.linear2_drop = nn.Dropout(0.2)\n",
        "        self.linear3 = nn.Linear(768, 576)\n",
        "        self.linear3_drop = nn.Dropout(0.1)\n",
        "        # output layer\n",
        "        self.linear4 = nn.Linear(576, output_size)\n",
        "        self.activation_function=activation_function\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Flatten images into vectors\n",
        "        out = x.view(x.size(0), -1)\n",
        "        # Apply layers & activation functions\n",
        "        out = self.linear1(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear1_drop(out)\n",
        "\n",
        "        out = self.linear2(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear2_drop(out)\n",
        "        \n",
        "        out = self.linear3(out)\n",
        "        # Apply activation function\n",
        "        if self.activation_function==\"relu\":\n",
        "          out = torch.nn.functional.relu(out)\n",
        "        if self.activation_function ==\"tanh\":\n",
        "          out = torch.nn.functional.tanh(out)\n",
        "        if self.activation_function ==\"sigmoid\":\n",
        "          out = torch.nn.functional.sigmoid(out)\n",
        "        # Apply Dropout\n",
        "        out = self.linear3_drop(out)\n",
        "        # Get predictions using output layer\n",
        "        out = self.linear4(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = my_cross_entropy(out, labels)\n",
        "        #print(loss)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        #torch.nn.functional.cross_entropy (out, labels)\n",
        "        loss = my_cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "\n",
        "input_size = 3*32*32\n",
        "output_size = 10\n",
        "model = CIFAR10Model(\"tanh\")\n",
        "log_interval=100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YWcYvpGUux"
      },
      "source": [
        "lambda2 = 0.001 # regularization hyperparameters\n",
        "lambda1 = 0\n",
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "# we train with l1 and l2 regularization\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch_idx,batch in enumerate(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            l2_regularization = 0\n",
        "            l1_regularization = 0\n",
        "            for param in model.parameters():\n",
        "              l2_regularization += torch.norm(param)**2\n",
        "              l1_regularization += torch.sum(torch.abs(param))\n",
        "\n",
        "            loss = loss + lambda2*l2_regularization + lambda1*l1_regularization\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            #if batch_idx % log_interval == 0:\n",
        "            #    print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
        "            #        epoch, batch_idx * len(batch[0]), len(train_dataset),\n",
        "            #        loss.item()))\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4t8_0vsGUux"
      },
      "source": [
        "'''\n",
        "Step 5: Move model and data to GPU if availble \n",
        "'''\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "    \n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)\n",
        "\n",
        "model = to_device(model, device)\n",
        "l2_regularization = torch.tensor(0)\n",
        "l2_regularization = to_device(l2_regularization, device).float()\n",
        "l1_regularization = torch.tensor(0)\n",
        "l1_regularization = to_device(l1_regularization, device).float()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJMyU1vZGUux",
        "outputId": "1a1fb954-9fd2-4927-cb47-0c1c96be6282"
      },
      "source": [
        "'''\n",
        "Step 5: Train Model\n",
        "'''\n",
        "history = [evaluate(model, val_loader)]\n",
        "history # initial Loss and accuracy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.12012289464473724, 'val_loss': 2.305201530456543}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUkhAYGUuy"
      },
      "source": [
        "#history += fit(10, 0.05, model, train_loader, val_loader)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1x5etBbXxqF"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1W4KZIXwo8"
      },
      "source": [
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X6aIEmhGUuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "ecff0568-f69a-4d86-a926-4d6037eeccf4"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#RMSProp and tanh = {'val_acc': 0.09674469381570816, 'val_loss': 37.956207275390625}\n",
        "#RMSProp and sigmoid {'val_acc': 0.10073761641979218, 'val_loss': 21.830883026123047}\n",
        "#RMSProp and relu {'val_acc': 0.0991738811135292, 'val_loss': 2.3054039478302}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.RMSprop)\n",
        "plot_losses(history)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 41.3646, val_acc: 0.0985\n",
            "Epoch [1], val_loss: 51.1861, val_acc: 0.0995\n",
            "Epoch [2], val_loss: 9.3576, val_acc: 0.1153\n",
            "Epoch [3], val_loss: 1247.9446, val_acc: 0.1004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-460de15c94a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.06\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0c45f2e97576>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml2_regularization\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml1_regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0FN-SP2cZWG"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-0ixo5icY3P"
      },
      "source": [
        "evaluate(model, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25JXZZ0JGUuy"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adadelta and tanh {'val_acc': 0.4410897195339203, 'val_loss': 1.5692006349563599}\n",
        "#Adadelta and sigmoid {'val_acc': 0.18444138765335083, 'val_loss': 2.0757439136505127}\n",
        "#Adadelta and relu {'val_acc': 0.495879203081131, 'val_loss': 1.4351319074630737}\n",
        "\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adadelta)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7DjM_R5ci-5"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA0Vo17rci1H"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7j70F3GGUuy"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adagrad and tanh {'val_acc': 0.2304287850856781, 'val_loss': 2.1180825233459473}\n",
        "#Adagrad and sigmoid {'val_acc': 0.0991738811135292, 'val_loss': 2.3229012489318848}\n",
        "#Adagrad and relu {'val_acc': 0.38202202320098877, 'val_loss': 1.717851161956787}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adagrad)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUHSGRp1cozY"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpE6zGfLcr8D"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Gn5aewGUu2"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#Adam and tanh {'val_acc': 0.09625294804573059, 'val_loss': 12.214295387268066}\n",
        "#Adam and sigmoid {'val_acc': 0.10023604333400726, 'val_loss': 2.4134914875030518}\n",
        "#Adam and relu {'val_acc': 0.10160306841135025, 'val_loss': 2086.643310546875}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adam)\n",
        "plot_losses(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCFRNB2Wc0jq"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmT6W-T7c0Tz"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jugQrquTGUu2"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "#SGD and tanh {'val_acc': 0.4307238459587097, 'val_loss': 1.5837513208389282}\n",
        "#SGD and sigmoid {'val_acc': 0.16859754920005798, 'val_loss': 2.1040098667144775}\n",
        "#SGD and relu {'val_acc': 0.46284419298171997, 'val_loss': 1.4877265691757202}\n",
        "model = CIFAR10Model(\"relu\")\n",
        "model = to_device(model, device)\n",
        "\n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.SGD)\n",
        "plot_losses(history)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlGQPK5qc5lD"
      },
      "source": [
        "plot_accuracies(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpqZPoPqc5Y0"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgSKeqM1GUu2"
      },
      "source": [
        "# best model found was \n",
        "history += fit(25, 0.06, model, train_loader, val_loader,opt_func=torch.optim.Adadelta)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnvzZpszGUu2"
      },
      "source": [
        "\"\"\"\n",
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "    \n",
        "plot_losses(history)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMA97ciXGUu2"
      },
      "source": [
        "\"\"\"\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "    \n",
        "plot_accuracies(history)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XjyZuE8GUu2"
      },
      "source": [
        "evaluate(model, test_loader) # its displayed as validation loss and accuracy, but this is the test loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqvcEkYKzWDp"
      },
      "source": [
        "###Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QofMApb3zVPI"
      },
      "source": [
        "import numpy as np\n",
        "cm = np.zeros((10, 10), int)\n",
        "model = to_device(model, \"cpu\")\n",
        "for i in range(len(test_dataset)):\n",
        "  data = test_dataset[i][0]\n",
        "  label = test_dataset[i][1]\n",
        "  data = data.view(1,data.shape[0],data.shape[1],data.shape[2])\n",
        "  predict = model.forward(data)\n",
        "  target = label\n",
        "  cm[predict.argmax(), target] += 1\n",
        "print(cm)\n",
        "    #print(data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25bkpNjSIzF3"
      },
      "source": [
        "### Hyper Parameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awYBftOpI5aH"
      },
      "source": [
        "\"\"\"\n",
        "from hyperopt import hp, tpe, fmin\n",
        "def run_model(learning_rate):\n",
        "  model = CIFAR10Model()\n",
        "  model = to_device(model, device)\n",
        "  error = fit(1, learning_rate, model, train_loader, val_loader)\n",
        "  return error[-1][\"val_loss\"]\n",
        "\n",
        "\n",
        "best = fmin(fn=lambda x: run_model(x),\n",
        "            space=hp.uniform('x', 0.01, 1),\n",
        "            algo=tpe.suggest, \n",
        "            max_evals=100)\n",
        "print(\"Best Learning Rate\",best)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibXP4GouOS8w"
      },
      "source": [
        "\"\"\"\n",
        "def run_model(batch_size):\n",
        "  model = CIFAR10Model()\n",
        "  batch_size=batch_size\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n",
        "  train_loader = DeviceDataLoader(train_loader, device)\n",
        "  val_loader = DeviceDataLoader(val_loader, device)\n",
        "  test_loader = DeviceDataLoader(test_loader, device)\n",
        "  model = to_device(model, device)\n",
        "  error = fit(1, 0.06, model, train_loader, val_loader)\n",
        "  return error[-1][\"val_loss\"]\n",
        "\n",
        "\n",
        "best = fmin(fn=lambda x: run_model(x),\n",
        "            space=hp.choice('x',[1,32,64,124,256,512,1024]),\n",
        "            algo=tpe.suggest, \n",
        "            max_evals=10)\n",
        "print(\"Best Batch Size\",best)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}